#!/usr/bin/env python3
"""
Experiment: exp06c_lgbm_bin_sspace_elementwise_reduced_nestedcv_bliss005_cv2 (HALO-S-CV2)

Config
- task: binary classification (synergy vs antagonism), with “synergy” treated as the positive class
- feature_design: reduced elementwise similarity features (selected in exp05c; S-space included)
- use_sspace: true (already baked into the reduced feature matrix; no feature recomputation here)
- outer_cv: CV2-style held-out evaluation (strain + drug-pair disjoint)
    - five independent brute-force CV2 splits are generated by selecting test-strain subsets
      such that the induced test set size falls within predefined row-fraction bands
    - training excludes all rows containing any test strains or any drug pairs induced by test strains
    - cross-edge rows violating disjointness are dropped by construction
- inner_cv: 3-fold hyperparameter search on the outer-train set using StratifiedGroupKFold
    - grouping variable: Drug Pair
    - 32 LightGBM configurations sampled from a fixed search space
    - best configuration selected by mean inner-CV accuracy
- evaluation: for each outer split, refit on the full outer-train set and evaluate once on the outer-test set

Outputs (MODEL_RESULTS/exp06c_lgbm_bin_sspace_elementwise_reduced_nestedcv_bliss005_cv2):
- cv2_info_fold{k}.json        : metadata describing each brute-force CV2 split (test strains/pairs, kept/dropped rows)
- metrics_per_fold.csv         : per-split metrics (ROC AUC, accuracy, F1, per-class precision/recall/F1)
- confusion_matrix_cv2_allfolds.png : aggregated confusion matrix summed over the five outer splits

**Data integrity note:**
All preprocessing (NA handling, dtype enforcement, column validation, etc.) was completed upstream.
This script assumes clean, validated input data.
"""

import json
import itertools

import numpy as np
import pandas as pd
import lightgbm as lgb
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from sklearn.model_selection import StratifiedGroupKFold, GroupKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    roc_auc_score,
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay,
    precision_recall_fscore_support,
)

from halo.paths import MODEL_RESULTS

# =====================================================================
# 1) Brute-force CV2 split generator
# =====================================================================
def brute_force_cv2_split(
    df,
    strain_col,
    pair_col,
    min_frac,
    max_frac,
    lambda_penalty=1.0,
    top_k_print=5,
    verbose=True,
):
    """
    Reproduces your original brute-force CV2 logic:
    - Select a test subset of strains
    - All pairs belonging to those strains become test
    - Train = rows not using test strains AND not using test pairs
    - Drops rows that conflict with disjointness
    Returns (train_idx, test_idx, info_dict)
    """

    S_all = df[strain_col].astype(str).values
    P_all = df[pair_col].astype(str).values
    strains_uni = sorted(np.unique(S_all).tolist())
    n_total = len(df)

    min_target = int(round(min_frac * n_total))
    max_target = int(round(max_frac * n_total))

    if verbose:
        print("=" * 72)
        print(
            f"Brute-force CV2: min_frac={min_frac:.2f}, max_frac={max_frac:.2f}, "
            f"target rows [{min_target}, {max_target}]"
        )

    # ---- Evaluate subset ----
    def eval_subset(S_test_set):
        if not S_test_set:
            return 0, 0, n_total, set(), -np.inf

        mask_s = np.isin(S_all, list(S_test_set))
        P_test_set = set(P_all[mask_s])
        test_mask = mask_s & np.isin(P_all, list(P_test_set))
        train_mask = (~mask_s) & (~np.isin(P_all, list(P_test_set)))

        kept = int(test_mask.sum())
        train = int(train_mask.sum())
        dropped = n_total - (kept + train)
        score = kept - lambda_penalty * dropped
        return kept, train, dropped, P_test_set, score

    # ---- Search ----
    candidates = []
    for r in range(1, len(strains_uni) + 1):
        for subset in itertools.combinations(strains_uni, r):
            S_test = set(subset)
            kept, train, dropped, P_test, score = eval_subset(S_test)
            if min_target <= kept <= max_target:
                candidates.append(
                    dict(
                        S_test=S_test,
                        P_test=P_test,
                        kept=kept,
                        train=train,
                        dropped=dropped,
                        score=score,
                    )
                )

    # ---- No candidates ----
    if not candidates:
        if verbose:
            print("No valid CV2 split found within band. Returning all-train.")
        return (
            np.arange(n_total),
            np.array([], dtype=int),
            dict(
                reason="no_candidates",
                test_strains=set(),
                test_pairs=set(),
                kept_test_rows=0,
                kept_train_rows=n_total,
                dropped_rows=0,
                params=dict(min_frac=min_frac, max_frac=max_frac),
            ),
        )

    # ---- Rank candidates: prefer fewest dropped, then largest kept ----
    candidates.sort(key=lambda c: (c["dropped"], -c["kept"], -c["score"]))

    best = candidates[0]
    S_test_best = best["S_test"]
    P_test_best = best["P_test"]

    test_mask = np.isin(S_all, list(S_test_best)) & np.isin(P_all, list(P_test_best))
    train_mask = (~np.isin(S_all, list(S_test_best))) & (~np.isin(P_all, list(P_test_best)))

    te_idx = np.where(test_mask)[0]
    tr_idx = np.where(train_mask)[0]
    dropped_rows = n_total - (te_idx.size + tr_idx.size)

    # ---- Info dict ----
    info = dict(
        mode="bruteforce_strains_pairs",
        test_strains=set(S_test_best),
        test_pairs=set(P_test_best),
        kept_test_rows=int(te_idx.size),
        kept_train_rows=int(tr_idx.size),
        dropped_rows=int(dropped_rows),
        params=dict(min_frac=min_frac, max_frac=max_frac, lambda_penalty=lambda_penalty),
        top_candidates=candidates[:top_k_print],
    )

    if verbose:
        print(
            f"BEST: test strains={len(S_test_best)}, test pairs={len(P_test_best)}, "
            f"kept={te_idx.size}, dropped={dropped_rows}"
        )

    return tr_idx, te_idx, info


# =====================================================================
# 2) MAIN EXPERIMENT
# =====================================================================
def main():
    SCHEME = "CV2"

    filtered_path = MODEL_RESULTS / "exp05c_lgbm_bin_sspace_elementwise_featselect_bliss005_cv2" / "elementwise_features_filtered_cv2.csv"

    out_dir = MODEL_RESULTS / "exp06c_lgbm_bin_sspace_elementwise_reduced_nestedcv_bliss005_cv2"
    out_dir.mkdir(parents=True, exist_ok=True)

    print("\n=== EXP06c (5-fold brute-force CV2) ===\n")

    # -----------------------------------------------------------------
    # Load data
    # -----------------------------------------------------------------
    df = pd.read_csv(filtered_path).copy()
    df = df[df["Interaction Type"].isin(["synergy", "antagonism"])].copy()

    drop_cols = [
        "Drug A", "Drug B", "Drug A Inchikey", "Drug B Inchikey",
        "Strain", "Specie", "Bliss Score", "Interaction Type",
        "Source", "Drug Pair",
    ]
    feat_cols = [c for c in df.columns if c not in drop_cols]
    X = df[feat_cols].copy()

    y = df["Interaction Type"].copy()
    le = LabelEncoder()
    y_enc = le.fit_transform(y)

    pairs = df["Drug Pair"].astype(str).values
    strains = df["Strain"].astype(str).values
    n = len(df)

    print("Total rows:", n)
    print("Features:", len(feat_cols))

    # =================================================================
    # 3) Make 5 brute-force CV2 folds with fixed min/max bands
    # =================================================================
    bands = [
        (0.16, 0.20),
        (0.18, 0.22),
        (0.20, 0.24),
        (0.22, 0.26),
        (0.24, 0.28),
    ]

    cv2_splits = []
    for k, (mn, mx) in enumerate(bands, 1):
        print(f"\n=== Brute-force CV2 fold {k} | target={mn:.2f}-{mx:.2f} ===")
        tr_idx, te_idx, info = brute_force_cv2_split(
            df, "Strain", "Drug Pair", mn, mx, lambda_penalty=1.0, verbose=True
        )
        cv2_splits.append((tr_idx, te_idx, info))

        # Save metadata
        with open(out_dir / f"cv2_info_fold{k}.json", "w") as f:
            json.dump(info, f, indent=2, default=lambda x: list(x))

    # =================================================================
    # 4) Nested CV and evaluation
    # =================================================================
    class SilentLogger:
        def info(self, msg): pass
        def warning(self, msg): pass

    lgb.register_logger(SilentLogger())

    rng = np.random.default_rng(42)

    fold_results = []
    cm_total = None

    synergy_code = le.transform(["synergy"])[0]
    ant_code = le.transform(["antagonism"])[0]

    # -----------------------------------------------------------------
    # Loop over the 5 CV2 folds
    # -----------------------------------------------------------------
    for fold_idx, (tr_idx, te_idx, info) in enumerate(cv2_splits, 1):
        print("\n" + "#" * 72)
        print(f"########## OUTER FOLD {fold_idx}/5 ##########")
        print("#" * 72)

        X_tr = X.iloc[tr_idx].reset_index(drop=True)
        X_te = X.iloc[te_idx].reset_index(drop=True)
        y_tr = y_enc[tr_idx]
        y_te = y_enc[te_idx]
        grp_tr = pairs[tr_idx]

        # -------------------------------------------------------------
        # Inner 3-fold CV grouped by pair
        # -------------------------------------------------------------
        def sample_one_params():
            max_depth = 3
            leaves_map = {3: [7, 9, 15]}
            return dict(
                boosting_type="gbdt",
                learning_rate=float(rng.choice([0.02, 0.03])),
                max_depth=max_depth,
                num_leaves=int(rng.choice(leaves_map[max_depth])),
                min_data_in_leaf=int(rng.choice([200, 300])),
                feature_fraction=float(rng.choice([0.30, 0.40, 0.50])),
                bagging_fraction=float(rng.choice([0.60, 0.70, 0.80])),
                bagging_freq=1,
                lambda_l2=float(10 ** rng.uniform(1.4, 1.9)),
                lambda_l1=float(rng.choice([0.0, 0.1, 0.5])),
                max_bin=int(rng.choice([63, 127])),
                min_gain_to_split=float(rng.choice([0.05, 0.10, 0.20])),
            )

        param_samples = [sample_one_params() for _ in range(32)]

        try:
            inner_cv = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=111)

            def inner_splitter():
                return inner_cv.split(X_tr, y_tr, groups=grp_tr)

        except Exception:
            inner_cv = GroupKFold(n_splits=3)

            def inner_splitter():
                return inner_cv.split(X_tr, y_tr, groups=grp_tr)

        def cv_acc_for_params(params):
            accs = []
            for tr_f, val_f in inner_splitter():
                Xf_tr, Xf_val = X_tr.iloc[tr_f], X_tr.iloc[val_f]
                yf_tr, yf_val = y_tr[tr_f], y_tr[val_f]
                m = lgb.LGBMClassifier(
                    objective="binary",
                    n_estimators=4000,
                    random_state=777,
                    n_jobs=4,
                    **params,
                )
                m.fit(
                    Xf_tr,
                    yf_tr,
                    eval_set=[(Xf_val, yf_val)],
                    eval_metric="binary_logloss",
                    callbacks=[lgb.early_stopping(100, False), lgb.log_evaluation(0)],
                )
                pred = m.predict(Xf_val)
                accs.append(accuracy_score(yf_val, pred))
            return float(np.mean(accs))

        print(f"\n--- Inner CV search ({len(param_samples)} configs) ---")
        scores = [(cv_acc_for_params(ps), ps) for ps in param_samples]
        scores.sort(reverse=True, key=lambda t: t[0])
        best_acc, best_params = scores[0]
        print(f"Best ACC: {best_acc:.3f}")
        print("Best params:", best_params)

        # -------------------------------------------------------------
        # Final refit on outer-train
        # -------------------------------------------------------------
        m_final = lgb.LGBMClassifier(
            objective="binary",
            n_estimators=4000,
            random_state=777,
            n_jobs=4,
            **best_params,
        )
        m_final.fit(X_tr, y_tr)

        pos_idx = np.flatnonzero(m_final.classes_ == synergy_code)[0]

        # -------------------------------------------------------------
        # Final evaluation
        # -------------------------------------------------------------
        p_te = m_final.predict_proba(X_te)[:, pos_idx]
        y_pred = (p_te >= 0.5).astype(int)
        y_te_bin = (y_te == synergy_code).astype(int)

        accuracy_test = accuracy_score(y_te, y_pred)
        f1_macro_test = f1_score(y_te, y_pred, average="macro")
        f1_weighted_test = f1_score(y_te, y_pred, average="weighted")
        roc_auc_test = roc_auc_score(y_te_bin, p_te)

        print(f"\n=== OUTER FOLD {fold_idx} RESULTS ===")
        print(f"AUC      : {roc_auc_test:.3f}")
        print(f"Acc      : {accuracy_test:.3f}")
        print(f"F1-macro : {f1_macro_test:.3f}")
        print(f"F1-w     : {f1_weighted_test:.3f}")
        print("\nReport:\n", classification_report(y_te, y_pred, target_names=le.classes_))

        prec, rec, f1s, _ = precision_recall_fscore_support(
            y_te, y_pred, labels=[ant_code, synergy_code]
        )
        precision_antag, precision_syn = prec
        recall_antag, recall_syn = rec
        f1_antag, f1_syn = f1s

        # -------------------------------------------------------------
        # Accumulate confusion matrix
        # -------------------------------------------------------------
        order_idx = le.transform(["antagonism", "synergy"])
        cm = confusion_matrix(y_te, y_pred, labels=order_idx)
        if cm_total is None:
            cm_total = cm.copy()
        else:
            cm_total += cm

        fold_results.append(
            dict(
                fold=fold_idx,
                roc_auc=roc_auc_test,
                accuracy=accuracy_test,
                f1_macro=f1_macro_test,
                f1_weighted=f1_weighted_test,
                precision_antag=precision_antag,
                recall_antag=recall_antag,
                f1_antag=f1_antag,
                precision_syn=precision_syn,
                recall_syn=recall_syn,
                f1_syn=f1_syn,
            )
        )

    # =================================================================
    # 5) Summary across folds
    # =================================================================
    print("\n" + "=" * 72)
    print("=== SUMMARY ACROSS 5 CV2 FOLDS ===")
    for metric in ["roc_auc", "accuracy", "f1_macro", "f1_weighted"]:
        vals = [fr[metric] for fr in fold_results]
        print(f"{metric}_mean={np.mean(vals):.4f}  {metric}_std={np.std(vals):.4f}")

    # Save summary
    pd.DataFrame(fold_results).to_csv(out_dir / "metrics_per_fold.csv", index=False)

    # =================================================================
    # 6) Save aggregated confusion matrix
    # =================================================================
    if cm_total is not None:
        order = ["antagonism", "synergy"]
        fig, ax = plt.subplots(figsize=(6, 5))
        disp = ConfusionMatrixDisplay(confusion_matrix=cm_total, display_labels=order)
        disp.plot(cmap="Blues", ax=ax, values_format="d")
        ax.set_title("Aggregated Confusion Matrix (5-fold CV2)", fontsize=13)
        plt.tight_layout()
        plt.savefig(out_dir / "confusion_matrix_cv2_allfolds.png", dpi=150)
        plt.close()

    print("\n=== EXP06c DONE (5-fold brute-force CV2) ===\n")


if __name__ == "__main__":
    main()
